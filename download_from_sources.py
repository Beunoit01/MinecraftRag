#!/usr/bin/env python3
"""
Script pour t√©l√©charger et traiter les PDFs climatiques depuis sources.txt
Optimis√© pour la qualit√© et le fact-checking
"""

import requests
import os
from pathlib import Path
import time
from urllib.parse import urlparse
import hashlib

# Configuration
SOURCES_FILE = "sources.txt"
OUTPUT_DIR = "climate_pdfs_quality"
DELAY_BETWEEN_DOWNLOADS = 2  # Respectueux
MAX_RETRIES = 3

def read_sources_file():
    """Lit le fichier sources.txt et retourne la liste des URLs."""
    try:
        with open(SOURCES_FILE, 'r', encoding='utf-8') as f:
            urls = [line.strip() for line in f if line.strip() and not line.startswith('#')]
        return [url for url in urls if url.startswith('http')]
    except FileNotFoundError:
        print(f"‚ùå Fichier {SOURCES_FILE} non trouv√©")
        return []

def get_filename_from_url(url):
    """G√©n√®re un nom de fichier appropri√© depuis l'URL."""
    parsed = urlparse(url)
    
    # Extraire le nom depuis l'URL
    if parsed.path.endswith('.pdf'):
        filename = os.path.basename(parsed.path)
    else:
        # Cr√©er un nom bas√© sur l'URL
        url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
        filename = f"document_{url_hash}.pdf"
    
    # Nettoyer le nom de fichier
    filename = filename.replace('%20', '_').replace('%', '_')
    
    return filename

def download_pdf(url, max_retries=MAX_RETRIES):
    """T√©l√©charge un PDF avec gestion des erreurs et des tentatives."""
    filename = get_filename_from_url(url)
    filepath = os.path.join(OUTPUT_DIR, filename)
    
    # V√©rifier si d√©j√† t√©l√©charg√©
    if os.path.exists(filepath):
        size_mb = os.path.getsize(filepath) / (1024 * 1024)
        print(f"    ‚è≠Ô∏è  D√©j√† t√©l√©charg√©: {filename} ({size_mb:.1f} MB)")
        return True, filename, size_mb
    
    print(f"    üì• T√©l√©chargement: {filename}")
    print(f"        URL: {url}")
    
    for attempt in range(max_retries):
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Linux; Climate Research) AppleWebKit/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=60, stream=True)
            response.raise_for_status()
            
            # V√©rifier le type de contenu
            content_type = response.headers.get('content-type', '').lower()
            if 'pdf' not in content_type and 'application/octet-stream' not in content_type:
                print(f"        ‚ö†Ô∏è  Type de contenu inattendu: {content_type}")
            
            # T√©l√©charger
            with open(filepath, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            
            # V√©rifier la taille
            size_mb = os.path.getsize(filepath) / (1024 * 1024)
            if size_mb < 0.1:  # Moins de 100KB = probablement une erreur
                print(f"        ‚ö†Ô∏è  Fichier tr√®s petit ({size_mb:.1f} MB), possible erreur")
                os.remove(filepath)
                return False, filename, 0
            
            print(f"        ‚úÖ Succ√®s: {filename} ({size_mb:.1f} MB)")
            return True, filename, size_mb
            
        except requests.exceptions.RequestException as e:
            print(f"        ‚ùå Tentative {attempt + 1}/{max_retries} √©chou√©e: {e}")
            if attempt < max_retries - 1:
                time.sleep(5)  # Attendre avant la prochaine tentative
            continue
    
    print(f"        ‚ùå √âchec d√©finitif apr√®s {max_retries} tentatives")
    return False, filename, 0

def categorize_source(url, filename):
    """Cat√©gorise le type de source bas√© sur l'URL."""
    url_lower = url.lower()
    filename_lower = filename.lower()
    
    if 'spm' in url_lower or 'summaryforpolicymakers' in filename_lower:
        return "üìã Summary for Policymakers"
    elif 'faq' in url_lower:
        return "‚ùì FAQ"
    elif 'srocc' in url_lower:
        return "üåä Ocean & Cryosphere"
    elif 'srccl' in url_lower:
        return "üå± Land Use"
    elif 'ar6' in url_lower:
        return "üìä AR6 Report"
    elif 'ar5' in url_lower:
        return "üìà AR5 Report"
    elif 'ajph' in url_lower:
        return "üì∞ Journal Article"
    else:
        return "üìÑ Document"

def main():
    """Fonction principale."""
    print("üåç T√âL√âCHARGEMENT DES SOURCES CLIMATIQUES DE QUALIT√â")
    print("="*60)
    
    # Cr√©er le dossier de sortie
    Path(OUTPUT_DIR).mkdir(exist_ok=True)
    
    # Lire les sources
    urls = read_sources_file()
    if not urls:
        print("‚ùå Aucune URL trouv√©e dans sources.txt")
        return
    
    print(f"üìö {len(urls)} sources √† t√©l√©charger")
    print("-" * 60)
    
    # Statistiques
    successful_downloads = 0
    total_size_mb = 0
    categories = {}
    
    for i, url in enumerate(urls, 1):
        print(f"\n[{i}/{len(urls)}] Traitement de la source")
        
        success, filename, size_mb = download_pdf(url)
        
        if success:
            successful_downloads += 1
            total_size_mb += size_mb
            
            # Cat√©goriser
            category = categorize_source(url, filename)
            categories[category] = categories.get(category, 0) + 1
        
        # Pause entre t√©l√©chargements
        if i < len(urls):
            time.sleep(DELAY_BETWEEN_DOWNLOADS)
    
    # R√©sum√©
    print("\n" + "="*60)
    print("üìä R√âSUM√â DU T√âL√âCHARGEMENT")
    print("="*60)
    print(f"‚úÖ Succ√®s: {successful_downloads}/{len(urls)} PDFs")
    print(f"üíæ Taille totale: {total_size_mb:.1f} MB")
    print(f"üìÅ Dossier: {OUTPUT_DIR}")
    
    print(f"\nüìö R√âPARTITION PAR CAT√âGORIE:")
    for category, count in sorted(categories.items()):
        print(f"   {category}: {count} document(s)")
    
    if successful_downloads > 0:
        print(f"\nüéØ PROCHAINES √âTAPES:")
        print(f"   1. Installer: pip install pdfplumber")
        print(f"   2. Extraire le texte: python extract_pdf_text.py")
        print(f"   3. Continuer avec le pipeline RAG")
    
    print(f"\nüí° QUALIT√â ATTENDUE: EXCELLENTE")
    print(f"   ‚Ä¢ Sources officielles IPCC")
    print(f"   ‚Ä¢ Documents optimis√©s pour le fact-checking")
    print(f"   ‚Ä¢ Format PDF = texte propre et structur√©")

if __name__ == "__main__":
    main()
